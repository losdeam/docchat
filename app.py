import gradio as gr
import hashlib
from typing import List, Dict
import os
from datetime import datetime

from document_processor import DoclingProcessor
from retriever import RetrieverBuilder
from retriever.post_processor import deduplicate_documents, limit_documents
from agents.workflow import AgentWorkflow
from config import constants
from config.settings import settings
from utils.logging import logger, set_log_level
from utils.cache_queue import initialize_cache_queue
from langchain_community.vectorstores import Chroma

# 1) Define some example data 
#    (i.e., question + paths to documents relevant to that question).
EXAMPLES = {
    "Google 2024 Environmental Report": {
        "question": "Retrieve the data center PUE efficiency values in Singapore 2nd facility in 2019 and 2022. Also retrieve regional average CFE in Asia pacific in 2023",
        "file_paths": ["examples/google-2024-environmental-report.pdf"]  
    },
    "DeepSeek-R1 Technical Report": {
        "question": "Summarize DeepSeek-R1 model's performance evaluation on all coding tasks against OpenAI o1-mini model",
        "file_paths": ["examples/DeepSeek Technical Report.pdf"]
    }
}

# å­˜å‚¨åå¤„ç†é…ç½®çš„å…¨å±€å˜é‡
post_processing_config = {
    "enable_deduplication": True,
    "max_results": settings.VECTOR_SEARCH_K
}

def parse_weights(weight_str):
    """è§£ææƒé‡å­—ç¬¦ä¸²ä¸ºåˆ—è¡¨"""
    try:
        # ç§»é™¤ç©ºæ ¼å¹¶è§£æåˆ—è¡¨
        weight_str = weight_str.replace(" ", "")
        if weight_str.startswith('[') and weight_str.endswith(']'):
            weights = [float(x) for x in weight_str[1:-1].split(',')]
            if len(weights) == 2:
                return weights
    except:
        pass
    return [0.5, 0.5]  # é»˜è®¤æƒé‡

def get_current_settings():
    """è·å–å½“å‰é…ç½®è®¾ç½®"""
    return {
        "LOG_LEVEL": settings.LOG_LEVEL,
        "VECTOR_SEARCH_K": settings.VECTOR_SEARCH_K,
        "HYBRID_RETRIEVER_WEIGHTS": settings.HYBRID_RETRIEVER_WEIGHTS,
        "CACHE_EXPIRE_DAYS": settings.CACHE_EXPIRE_DAYS,
        "CHROMA_DB_PATH": settings.CHROMA_DB_DEFAULT_PATH,
        "CHROMA_COLLECTION_NAME": settings.CHROMA_DEFAULT_COLLECTION_NAME
    }

def update_settings(log_level, vector_search_k, hybrid_weights, cache_expire_days, 
                   chroma_db_path, chroma_collection_name, enable_deduplication, max_results):
    """æ›´æ–°é…ç½®è®¾ç½®"""
    try:
        # è§£ææ··åˆæ£€ç´¢æƒé‡
        weights = parse_weights(hybrid_weights)
        
        # æ›´æ–°æ—¥å¿—çº§åˆ«
        settings.LOG_LEVEL = log_level
        set_log_level(log_level)
        
        # æ›´æ–°æ£€ç´¢è®¾ç½®
        settings.VECTOR_SEARCH_K = int(vector_search_k)
        settings.HYBRID_RETRIEVER_WEIGHTS = weights
        settings.CACHE_EXPIRE_DAYS = int(cache_expire_days)
        
        # æ›´æ–°åå¤„ç†è®¾ç½®
        post_processing_config["enable_deduplication"] = enable_deduplication
        post_processing_config["max_results"] = int(max_results)
        
        # æ›´æ–°æ•°æ®åº“è®¾ç½®
        settings.CHROMA_DB_DEFAULT_PATH = chroma_db_path
        settings.CHROMA_DEFAULT_COLLECTION_NAME = chroma_collection_name
        
        # ä¿å­˜åˆ°ç¯å¢ƒå˜é‡ï¼Œä»¥ä¾¿å…¶ä»–è¿›ç¨‹å¯ä»¥è®¿é—®
        os.environ["LOG_LEVEL"] = log_level
        os.environ["VECTOR_SEARCH_K"] = str(vector_search_k)
        os.environ["HYBRID_RETRIEVER_WEIGHTS"] = str(weights)
        os.environ["CACHE_EXPIRE_DAYS"] = str(cache_expire_days)
        os.environ["CHROMA_DB_PATH"] = chroma_db_path
        os.environ["CHROMA_COLLECTION_NAME"] = chroma_collection_name
        
        return "âœ… è®¾ç½®å·²æˆåŠŸæ›´æ–°ï¼è¯·æ³¨æ„ï¼šæŸäº›è®¾ç½®å¯èƒ½éœ€è¦é‡å¯åº”ç”¨æ‰èƒ½å®Œå…¨ç”Ÿæ•ˆã€‚", get_current_settings()
    except Exception as e:
        return f"âŒ æ›´æ–°è®¾ç½®æ—¶å‡ºé”™: {str(e)}", get_current_settings()

def import_documents_to_kb(files: List) -> str:
    """å¯¼å…¥æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    try:
        if not files:
            return "âŒ æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"
            
        # importer = KnowledgeBaseImporter()
        result = ""
        return f"âœ… {result}"
    except Exception as e:
        logger.error(f"å¯¼å…¥æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
        return f"âŒ å¯¼å…¥æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}"

def list_knowledge_base_contents():
    """åˆ—å‡ºçŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£"""
    # TODO: è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å‡½æ•°ï¼Œå…·ä½“å®ç°å°†åœ¨åç»­å¼€å‘ä¸­å®Œæˆ
    return "ğŸ“š çŸ¥è¯†åº“å†…å®¹åˆ—è¡¨åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­..."

def clear_knowledge_base():
    """æ¸…ç©ºçŸ¥è¯†åº“"""
    # TODO: è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å‡½æ•°ï¼Œå…·ä½“å®ç°å°†åœ¨åç»­å¼€å‘ä¸­å®Œæˆ
    return "ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­..."

def create_knowledge_base_config(name, description, embedding_model):
    """åˆ›å»ºæ–°çš„çŸ¥è¯†åº“é…ç½®"""
    # TODO: è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å‡½æ•°ï¼Œå…·ä½“å®ç°å°†åœ¨åç»­å¼€å‘ä¸­å®Œæˆ
    if not name.strip():
        return "âŒ çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©º"
    
    return f"âœ… çŸ¥è¯†åº“é…ç½®åˆ›å»ºåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...\n\né…ç½®è¯¦æƒ…:\n- åç§°: {name}\n- æè¿°: {description}\n- åµŒå…¥æ¨¡å‹: {embedding_model}"

def main():
    # åˆå§‹åŒ–ç¼“å­˜é˜Ÿåˆ—ç®¡ç†å™¨
    cache_queue_manager = initialize_cache_queue()
    
    # åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
    processor = DoclingProcessor()
    workflow = AgentWorkflow()

    # Define custom CSS for styling
    css = """
    .title {
        font-size: 1.5em !important; 
        text-align: center !important;
        color: #FFD700; 
    }

    .subtitle {
        font-size: 1em !important; 
        text-align: center !important;
        color: #FFD700; 
    }

    .text {
        text-align: center;
    }
    
    .tabs {
        background-color: #f9f9f9;
        border-radius: 10px;
        padding: 20px;
    }
    
    #config-button, #back-button {
        margin-bottom: 15px;
        align-self: flex-end;
    }
    
    """

    js = """
    function createGradioAnimation() {
        var container = document.createElement('div');
        container.id = 'gradio-animation';
        container.style.fontSize = '2em';
        container.style.fontWeight = 'bold';
        container.style.textAlign = 'center';
        container.style.marginBottom = '20px';
        container.style.color = '#eba93f';

        var text = 'Welcome to DocChat ğŸ¥!';
        for (var i = 0; i < text.length; i++) {
            (function(i){
                setTimeout(function(){
                    var letter = document.createElement('span');
                    letter.style.opacity = '0';
                    letter.style.transition = 'opacity 0.1s';
                    letter.innerText = text[i];

                    container.appendChild(letter);

                    setTimeout(function() {
                        letter.style.opacity = '0.9';
                    }, 50);
                }, i * 250);
            })(i);
        }

        var gradioContainer = document.querySelector('.gradio-container');
        gradioContainer.insertBefore(container, gradioContainer.firstChild);

        return 'Animation created';
    }
    """

    with gr.Blocks( title="DocChat ğŸ¥") as demo:
        # æ³¨å…¥ CSS
        gr.HTML(f"<style>{css}</style>")

        # æ³¨å…¥ JS
        gr.HTML(f"<script>{js}</script>")
        with gr.Tabs():
            with gr.TabItem("ğŸ  ä¸»ç•Œé¢"):
                gr.Markdown("## DocChat: powered by Docling ğŸ¥ and LangGraph", elem_classes="subtitle")
                gr.Markdown("# How it works âœ¨:", elem_classes="title")
                gr.Markdown("ğŸ“¤ Upload your document(s), enter your query then press Submit ğŸ“", elem_classes="text")
                gr.Markdown("Or you can select one of the examples from the drop-down menu, select Load Example then press Submit ğŸ“", elem_classes="text")
                gr.Markdown("âš ï¸ **Note:** DocChat only accepts documents in these formats: '.pdf', '.docx', '.txt', '.md'", elem_classes="text")

                # 2) Maintain the session state for retrieving doc changes
                session_state = gr.State({
                    "file_hashes": frozenset(),
                    "retriever": None
                })

                # 3) Layout 
                with gr.Row():
                    with gr.Column():
                        # Section for Examples
                        gr.Markdown("### Example ğŸ“‚")
                        example_dropdown = gr.Dropdown(
                            label="Select an Example ğŸ¥",
                            choices=list(EXAMPLES.keys()),
                            value=None,  # initially unselected
                        )
                        load_example_btn = gr.Button("Load Example ğŸ› ï¸")

                        # Standard input components
                        files = gr.Files(label="ğŸ“„ Upload Documents", file_types=constants.ALLOWED_TYPES)
                        question = gr.Textbox(label="â“ Question", lines=3)
                        
                        # Log level control
                        with gr.Accordion("ğŸ”§ Advanced Settings", open=False):
                            log_level = gr.Radio(
                                choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                                value=settings.LOG_LEVEL,
                                label="Log Level"
                            )
                            def change_log_level(level):
                                set_log_level(level)
                                # åŒæ­¥æ›´æ–°åˆ°ç¯å¢ƒå˜é‡
                                os.environ["LOG_LEVEL"] = level
                                return f"Log level changed to {level}"
                            
                            log_level.change(
                                fn=change_log_level,
                                inputs=log_level,
                                outputs=gr.Textbox(label="Status", interactive=False)
                            )

                        submit_btn = gr.Button("Submit ğŸš€")
                        
                    with gr.Column():
                        answer_output = gr.Textbox(label="ğŸ¥ Answer", interactive=False)
                        verification_output = gr.Textbox(label="âœ… Verification Report")

                # 4) Helper function to load example into the UI
                def load_example(example_key: str):
                    """
                    Given a key like 'Example 1', 
                    read the relevant docs from disk and return
                    them as file-like objects, plus the example question.
                    """
                    if not example_key or example_key not in EXAMPLES:
                        return [], ""  # blank if not found

                    ex_data = EXAMPLES[example_key]
                    question = ex_data["question"]
                    file_paths = ex_data["file_paths"]

                    # Prepare the file list to return. We read them from disk to
                    # give Gradio something it can handle as "uploaded" files.
                    loaded_files = []
                    for path in file_paths:
                        if os.path.exists(path):
                            # Gradio can accept a path directly, or a file-like object
                            loaded_files.append(path)
                        else:
                            logger.warning(f"File not found: {path}")

                    # The function can return lists matching the outputs we define below
                    return loaded_files, question

                load_example_btn.click(
                    fn=load_example,
                    inputs=[example_dropdown],
                    outputs=[files, question]
                )

                # 5) Standard flow for question submission
                def process_question(question_text: str, uploaded_files: List, state: Dict):
                    """Handle questions with document caching."""
                    
                    try:
                        if not question_text.strip():
                            raise ValueError("âŒ Question cannot be empty")
                        if not uploaded_files:
                            raise ValueError("âŒ No documents uploaded")

                        current_hashes = _get_file_hashes(uploaded_files)
                        
                        if state["retriever"] is None or current_hashes != state["file_hashes"]:
                            logger.info("Processing new/changed documents...")
                            chunks = processor.process(uploaded_files)
                            # é‡æ–°åˆ›å»ºæ£€ç´¢å™¨æ„å»ºå™¨ä»¥åº”ç”¨æœ€æ–°çš„åå¤„ç†é…ç½®
                            local_retriever_builder = RetrieverBuilder()
                            # ä½¿ç”¨æ–°çš„build_retrieveræ–¹æ³•
                            retriever = local_retriever_builder.build_retriever(chunks)
                            
                            state.update({
                                "file_hashes": current_hashes,
                                "retriever": retriever
                            })
                        
                        result = workflow.full_pipeline(
                            question=question_text,
                            retriever=state["retriever"]
                        )
                        
                        return result["draft_answer"], result["verification_report"], state
                    
                    except Exception as e:
                        logger.error(f"Processing error: {str(e)}")
                        return f"âŒ Error: {str(e)}", "", state

                submit_btn.click(
                    fn=process_question,
                    inputs=[question, files, session_state],
                    outputs=[answer_output, verification_output, session_state]
                )
            
            with gr.TabItem("ğŸ“¥ å¯¼å…¥çŸ¥è¯†åº“"):
                gr.Markdown("# ğŸ—ƒï¸ å¯¼å…¥æ–‡æ¡£åˆ°çŸ¥è¯†åº“")
                gr.Markdown("å°†æ–‡æ¡£å¯¼å…¥åˆ°æŒä¹…åŒ–çŸ¥è¯†åº“ä¸­ï¼Œä»¥ä¾¿åç»­æŸ¥è¯¢ä½¿ç”¨")
                
                with gr.Row():
                    with gr.Column():
                        kb_files = gr.Files(label="ğŸ“„ é€‰æ‹©è¦å¯¼å…¥çš„æ–‡æ¡£", file_types=constants.ALLOWED_TYPES)
                        import_btn = gr.Button("ğŸ“¥ å¯¼å…¥åˆ°çŸ¥è¯†åº“", variant="primary")
                        import_output = gr.Textbox(label="å¯¼å…¥ç»“æœ", interactive=False)
                        
                        import_btn.click(
                            fn=import_documents_to_kb,
                            inputs=[kb_files],
                            outputs=[import_output]
                        )
                        
                        gr.Markdown("## ğŸ“– ä½¿ç”¨è¯´æ˜")
                        gr.Markdown("""
                        1. é€‰æ‹©è¦å¯¼å…¥çš„æ–‡æ¡£æ–‡ä»¶
                        2. ç‚¹å‡»"å¯¼å…¥åˆ°çŸ¥è¯†åº“"æŒ‰é’®
                        3. ç­‰å¾…å¯¼å…¥å®Œæˆï¼ŒæŸ¥çœ‹å¯¼å…¥ç»“æœ
                        4. å¯¼å…¥çš„æ–‡æ¡£å°†ä¿å­˜åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œä¾›åç»­æŸ¥è¯¢ä½¿ç”¨
                        
                        **æ³¨æ„**: å¯¼å…¥çš„æ–‡æ¡£å°†è¢«å¤„ç†å¹¶å­˜å‚¨åœ¨é…ç½®çš„Chromaæ•°æ®åº“è·¯å¾„ä¸­ã€‚
                        """)
            
            with gr.TabItem("ğŸ” æŸ¥è¯¢çŸ¥è¯†åº“"):
                gr.Markdown("# ğŸ” ä»çŸ¥è¯†åº“æŸ¥è¯¢")
                gr.Markdown("ç›´æ¥ä»å·²æœ‰çš„çŸ¥è¯†åº“ä¸­æŸ¥è¯¢ä¿¡æ¯ï¼Œæ— éœ€é‡æ–°ä¸Šä¼ æ–‡æ¡£")
                
                with gr.Row():
                    with gr.Column():
                        kb_question = gr.Textbox(label="â“ é—®é¢˜", lines=3)
                        query_btn = gr.Button("ğŸ” æŸ¥è¯¢çŸ¥è¯†åº“", variant="primary")
                        
                    with gr.Column():
                        kb_answer_output = gr.Textbox(label="ğŸ¥ ç­”æ¡ˆ", interactive=False)
                        kb_verification_output = gr.Textbox(label="âœ… éªŒè¯æŠ¥å‘Š")
                
                # æŸ¥è¯¢çŸ¥è¯†åº“çš„çŠ¶æ€
                kb_session_state = gr.State({
                    "retriever": None
                })
                
                def query_knowledge_base(question_text: str, state: Dict):
                    """ç›´æ¥ä»çŸ¥è¯†åº“æŸ¥è¯¢"""
                    try:
                        if not question_text.strip():
                            raise ValueError("âŒ Question cannot be empty")
                            
                        # å¦‚æœè¿˜æ²¡æœ‰åŠ è½½æ£€ç´¢å™¨ï¼Œåˆ™ä»çŸ¥è¯†åº“åŠ è½½
                        if state["retriever"] is None:
                            logger.info("Loading retriever from knowledge base...")
                            state["retriever"] = None
                        
                        # ä½¿ç”¨å·²æœ‰çš„æ£€ç´¢å™¨å¤„ç†é—®é¢˜
                        result = workflow.full_pipeline(
                            question=question_text,
                            retriever=state["retriever"]
                        )
                        
                        return result["draft_answer"], result["verification_report"], state
                        
                    except Exception as e:
                        logger.error(f"Query error: {str(e)}")
                        return f"âŒ Error: {str(e)}", "", state
                
                query_btn.click(
                    fn=query_knowledge_base,
                    inputs=[kb_question, kb_session_state],
                    outputs=[kb_answer_output, kb_verification_output, kb_session_state]
                )
            
            with gr.TabItem("ğŸ“š çŸ¥è¯†åº“ç®¡ç†"):
                gr.Markdown("# ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
                gr.Markdown("æŸ¥çœ‹å’Œç®¡ç†çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£æ•°æ®")
                
                with gr.Row():
                    with gr.Column():
                        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°çŸ¥è¯†åº“å†…å®¹", variant="secondary")
                        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºçŸ¥è¯†åº“", variant="stop")
                        kb_status_output = gr.Textbox(label="çŸ¥è¯†åº“çŠ¶æ€", interactive=False, lines=10)
                    
                    with gr.Column():
                        gr.Markdown("## ğŸ†• æ–°å»ºçŸ¥è¯†åº“é…ç½®")
                        new_kb_name = gr.Textbox(label="çŸ¥è¯†åº“åç§°")
                        new_kb_description = gr.Textbox(label="çŸ¥è¯†åº“æè¿°", lines=3)
                        new_kb_embedding_model = gr.Dropdown(
                            label="åµŒå…¥æ¨¡å‹",
                            choices=["BAAI/bge-large-zh-v1.5", "BAAI/bge-m3", "sentence-transformers/all-MiniLM-L6-v2"],
                            value="BAAI/bge-large-zh-v1.5"
                        )
                        create_kb_btn = gr.Button("â• åˆ›å»ºçŸ¥è¯†åº“é…ç½®", variant="primary")
                        kb_config_output = gr.Textbox(label="é…ç½®ç»“æœ", interactive=False)
                
                def create_knowledge_base_config(name, description, embedding_model):
                    """åˆ›å»ºæ–°çš„çŸ¥è¯†åº“é…ç½®"""
                    if not name.strip():
                        return "âŒ çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©º"
                    
                    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šä¿å­˜é…ç½®åˆ°æ•°æ®åº“æˆ–æ–‡ä»¶
                    # ç›®å‰æˆ‘ä»¬åªæ˜¯æ¨¡æ‹Ÿè¿™ä¸ªè¿‡ç¨‹
                    config_info = f"""
çŸ¥è¯†åº“é…ç½®å·²åˆ›å»º:
ğŸ“Œ åç§°: {name}
ğŸ“ æè¿°: {description}
ğŸ¤– åµŒå…¥æ¨¡å‹: {embedding_model}
ğŸ•’ åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                    """
                    return f"âœ… {config_info.strip()}"
                
                def clear_knowledge_base():
                    """æ¸…ç©ºçŸ¥è¯†åº“"""
                    try:
                        chroma_path = settings.CHROMA_DB_PATH
                        if os.path.exists(chroma_path):
                            # åˆ é™¤Chromaæ•°æ®åº“ç›®å½•
                            import shutil
                            shutil.rmtree(chroma_path)
                            return "âœ… çŸ¥è¯†åº“å·²æ¸…ç©º"
                        else:
                            return "â„¹ï¸ çŸ¥è¯†åº“å·²ç»ä¸ºç©º"
                    except Exception as e:
                        logger.error(f"æ¸…ç©ºçŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")
                        return f"âŒ æ¸…ç©ºçŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}"
                
                # è®¾ç½®æŒ‰é’®ç‚¹å‡»äº‹ä»¶
                refresh_btn.click(
                    fn=list_knowledge_base_contents,
                    inputs=[],
                    outputs=[kb_status_output]
                )
                
                clear_btn.click(
                    fn=clear_knowledge_base,
                    inputs=[],
                    outputs=[kb_status_output]
                )
                
                create_kb_btn.click(
                    fn=create_knowledge_base_config,
                    inputs=[new_kb_name, new_kb_description, new_kb_embedding_model],
                    outputs=[kb_config_output]
                )
                
                # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨æ˜¾ç¤ºçŸ¥è¯†åº“å†…å®¹
                demo.load(
                    fn=list_knowledge_base_contents,
                    inputs=[],
                    outputs=[kb_status_output]
                )
            
            with gr.TabItem("âš™ï¸ é…ç½®ç®¡ç†"):
                gr.Markdown("# ğŸ› ï¸ DocChat é…ç½®ç®¡ç†")
                gr.Markdown("è°ƒæ•´åº”ç”¨çš„å„é¡¹é…ç½®å‚æ•°ã€‚è¯·æ³¨æ„ï¼ŒæŸäº›è®¾ç½®å¯èƒ½éœ€è¦é‡å¯åº”ç”¨æ‰èƒ½å®Œå…¨ç”Ÿæ•ˆã€‚")
                
                with gr.Row():
                    with gr.Column():
                        # æ—¥å¿—è®¾ç½®
                        gr.Markdown("## ğŸ“ æ—¥å¿—è®¾ç½®")
                        config_log_level = gr.Radio(
                            choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                            value=settings.LOG_LEVEL,
                            label="æ—¥å¿—çº§åˆ«"
                        )
                        
                        # æ£€ç´¢è®¾ç½®
                        gr.Markdown("## ğŸ” æ£€ç´¢è®¾ç½®")
                        config_vector_search_k = gr.Number(
                            value=settings.VECTOR_SEARCH_K,
                            label="å‘é‡æ£€ç´¢è¿”å›ç»“æœæ•°é‡ (VECTOR_SEARCH_K)",
                            precision=0
                        )
                        
                        config_hybrid_weights = gr.Textbox(
                            value=str(settings.HYBRID_RETRIEVER_WEIGHTS),
                            label="æ··åˆæ£€ç´¢æƒé‡ [BM25, Vector] (å¦‚: [0.5, 0.5])",
                            placeholder="è¯·è¾“å…¥æƒé‡åˆ—è¡¨ï¼Œä¾‹å¦‚: [0.4, 0.6]"
                        )
                        
                        # åå¤„ç†è®¾ç½®
                        gr.Markdown("## ğŸ”„ åå¤„ç†è®¾ç½®")
                        config_enable_deduplication = gr.Checkbox(
                            value=post_processing_config["enable_deduplication"],
                            label="å¯ç”¨æ–‡æ¡£å»é‡"
                        )
                        
                        config_max_results = gr.Number(
                            value=post_processing_config["max_results"],
                            label="æœ€å¤§è¿”å›ç»“æœæ•°",
                            precision=0
                        )
                        
                        # ç¼“å­˜è®¾ç½®
                        gr.Markdown("## ğŸ’¾ ç¼“å­˜ä¸å­˜å‚¨è®¾ç½®")
                        config_cache_expire_days = gr.Number(
                            value=settings.CACHE_EXPIRE_DAYS,
                            label="ç¼“å­˜è¿‡æœŸå¤©æ•° (CACHE_EXPIRE_DAYS)",
                            precision=0
                        )
                        
                        config_chroma_db_path = gr.Textbox(
                            value=settings.CHROMA_DB_PATH,
                            label="Chroma æ•°æ®åº“è·¯å¾„ (CHROMA_DB_PATH)"
                        )
                        
                        config_chroma_collection_name = gr.Textbox(
                            value=settings.CHROMA_COLLECTION_NAME,
                            label="Chroma é›†åˆåç§° (CHROMA_COLLECTION_NAME)"
                        )
                        
                        config_update_btn = gr.Button("ğŸ”„ æ›´æ–°è®¾ç½®", variant="primary")
                        gr.Markdown("*æ³¨æ„ï¼šéƒ¨åˆ†è®¾ç½®å¦‚æ•°æ®åº“è·¯å¾„ç­‰éœ€è¦é‡å¯åº”ç”¨æ‰èƒ½å®Œå…¨ç”Ÿæ•ˆ*")
                        
                    with gr.Column():
                        # æ˜¾ç¤ºå½“å‰è®¾ç½®
                        gr.Markdown("## âš™ï¸ å½“å‰è®¾ç½®")
                        current_settings_display = gr.JSON(
                            value=get_current_settings(),
                            label="å½“å‰é…ç½®å€¼"
                        )
                        
                        # æ›´æ–°çŠ¶æ€
                        config_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
                
                # è®¾ç½®æ›´æ–°æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶
                config_update_btn.click(
                    fn=update_settings,
                    inputs=[
                        config_log_level, 
                        config_vector_search_k, 
                        config_hybrid_weights, 
                        config_cache_expire_days, 
                        config_chroma_db_path, 
                        config_chroma_collection_name,
                        config_enable_deduplication,
                        config_max_results
                    ],
                    outputs=[config_status, current_settings_display]
                )
                
                # é¡µé¢åŠ è½½æ—¶æ˜¾ç¤ºå½“å‰è®¾ç½®
                demo.load(
                    fn=get_current_settings,
                    inputs=[],
                    outputs=[current_settings_display]
                )

    demo.launch(server_name="127.0.0.1", server_port=5000, share=False)

def _get_file_hashes(uploaded_files: List) -> frozenset:
    """Generate SHA-256 hashes for uploaded files."""
    hashes = set()
    for file in uploaded_files:
        with open(file.name, "rb") as f:
            hashes.add(hashlib.sha256(f.read()).hexdigest())
    return frozenset(hashes)

if __name__ == "__main__":
    main()