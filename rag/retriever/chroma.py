from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
from utils import get_single_hash,file_manager_activate
from config.settings import settings
import logging, os, pickle,json,itertools
from typing import List, Any
from langchain_core.documents import Document
from .base import BASE_KB
logger = logging.getLogger(__name__)

class Chroma_Retriever():
    def __init__(self, retrievers,weights,flags):
        """åˆå§‹åŒ–æ£€ç´¢å™¨åˆ—è¡¨ï¼Œä»¥åŠå¯¹åº”çš„æƒé‡ï¼Œä»¥åŠå¯¹åº”æ ‡è®°"""
        self.retrievers = retrievers
        self.weights = weights
        self.flags = flags

    def invoke(self, query: str):
        """è¿›è¡Œæ··åˆæ£€ç´¢"""
        combined = [] 
        # éå†æ¯ä¸ªæ£€ç´¢å™¨ï¼Œå¹¶ä½¿ç”¨æƒé‡è¿›è¡Œæ··åˆ
        for retriever, weight,flag in zip(self.retrievers, self.weights,self.flags):
            if flag in ["vector"]:
                docs = retriever.similarity_search_with_score(query)
            else:
                docs = retriever.invoke(query)

            for doc in docs:
                if type(doc) is tuple:
                    adjusted_score = doc[1] * weight
                    combined.append((doc[0], adjusted_score,flag))
                else:
                    adjusted_score = doc.metadata.get("score", 0) * weight
                    combined.append((doc, adjusted_score,flag))
        # æŒ‰è°ƒæ•´åçš„åˆ†æ•°é™åºæ’åº
        combined.sort(key=lambda x: x[1], reverse=True)
        # å»é‡ï¼šåŸºäºæ–‡æ¡£å†…å®¹
        seen_content = set()
        final_docs = []
        for doc, score, source in combined:
            content_snippet = doc.page_content[:100]  # ä½¿ç”¨å†…å®¹å‰100å­—ç¬¦ä½œä¸ºæ ‡è¯†
            if content_snippet not in seen_content: # å¦‚æœæ²¡æœ‰è§è¿‡ï¼Œåˆ™æ·»åŠ 
                seen_content.add(content_snippet)
                # å¤„ç†docæ²¡æœ‰metadataçš„æƒ…å†µ
                if not hasattr(doc, 'metadata') or doc.metadata is None:
                    doc.metadata = {}
                # å¯ä»¥é€‰æ‹©å°†åˆå¹¶åçš„åˆ†æ•°å­˜å…¥metadata
                doc.metadata["score"] = score
                doc.metadata["retrieval_source"] = source
                final_docs.append(doc)
        return final_docs

class Chroma_Builder(BASE_KB):
    def __init__(self, name: str = "default"):
        """Initialize the retriever builder with embeddings."""
        super().__init__(name)  # è°ƒç”¨åŸºç±»åˆå§‹åŒ–ï¼Œå³ä½¿ BASE_KB æ˜¯ç©ºå®ç°ä¹Ÿä¿æŒä¸€è‡´æ€§
        self.name = name
        self.retriever = None
        self.config = None
        self.embeddings = None
        self.parser = None
        self.docs = {}
        self.cache_dir = None
        self.config_path = None
        self.docs_dir = None

    def _get_doc_id(self, doc: Document) -> str:
        """ç”Ÿæˆæ–‡æ¡£å”¯ä¸€IDçš„è¾…åŠ©æ–¹æ³•"""
        import hashlib
        # å…³é”®ï¼šå°†é¡µé¢å†…å®¹å’Œæ ¸å¿ƒå…ƒæ•°æ®ï¼ˆå¦‚sourceï¼‰ä¸€èµ·å“ˆå¸Œ
        # æ’åºmetadata.items()æ˜¯ä¸ºäº†ä¿è¯å­—å…¸é¡ºåºä¸€è‡´
        content_to_hash = doc.page_content + str(sorted(doc.metadata.items()))
        return hashlib.sha256(content_to_hash.encode()).hexdigest()[:32] # å–å‰32ä½å·²è¶³å¤Ÿ

    def build_retriever(self, docs=None):
        """æ„å»ºä¸€ä¸ªç»“åˆBM25ä¸å‘é‡æ£€ç´¢çš„æ··åˆæ£€ç´¢å™¨ã€‚"""
        try:
            # ä½¿ç”¨ç”¨æˆ·è®¾ç½®æˆ–é»˜è®¤è®¾ç½®
            hybrid_retriever_weights = self.config.HYBRID_RETRIEVER_WEIGHTS
            
            # å¦‚æœæä¾›äº†docsåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™ä½¿ç”¨self.docs
            documents = docs if docs is not None else list(self.docs.values()) if isinstance(self.docs, dict) else list(itertools.chain.from_iterable(self.docs.values()))

            # å±•å¹³æ–‡æ¡£ï¼šå¦‚æœ self.docs æ˜¯å­—å…¸ï¼Œvalues() æ˜¯åˆ—è¡¨çš„åˆ—è¡¨ï¼Œåˆ™éœ€å±•å¹³
            if isinstance(documents, dict):
                documents = [doc for chunk_list in documents.values() for doc in chunk_list]
            elif isinstance(documents, list) and len(documents) > 0 and isinstance(documents[0], list):
                documents = [doc for sublist in documents for doc in sublist]

            # åˆ›å»ºä¸€ä¸ªç©ºçš„Chromaæ£€ç´¢å™¨
            vector_store = Chroma(embedding_function=self.embeddings, persist_directory=str(self.cache_dir))
            # è®¾ç½®ä¸€ä¸ªå®‰å…¨çš„æ‰¹æ¬¡å¤§å°ï¼Œè¿œä½äº64çš„é™åˆ¶ï¼Œä¸ºé•¿æ–‡æœ¬ç•™å‡ºtokenä½™é‡ã€‚
            embedding_batch_size = 32
            # 2. è®¡ç®—æ€»æ‰¹æ¬¡æ•°ï¼Œä¾¿äºæ˜¾ç¤ºè¿›åº¦
            total_batches = (len(documents) + embedding_batch_size - 1) // embedding_batch_size
            print(f"ğŸ“Š å¼€å§‹å¤„ç†ï¼Œå…±æœ‰ {len(documents)} ä¸ªæ–‡æ¡£ï¼Œéœ€åˆ†ä¸º {total_batches} æ‰¹è¿›è¡Œå‘é‡åŒ–ã€‚")
            # åˆ›å»ºChrom
                    
            for i in range(0, len(documents), embedding_batch_size):
                batch_num = (i // embedding_batch_size) + 1
                batch_docs = documents[i:i + embedding_batch_size]
                
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šä¸ºæ‰¹æ¬¡ç”ŸæˆåŸºäºå†…å®¹çš„ID ---
                batch_ids = [self._get_doc_id(doc) for doc in batch_docs]
                
                print(f"ğŸ”„ å¤„ç†ç¬¬ {batch_num} æ‰¹ï¼Œæœ¬æ‰¹ {len(batch_docs)} ä¸ªæ–‡æ¡£...")
                try:
                    # ä½¿ç”¨ ids å‚æ•°ã€‚å¯¹äºChromaï¼Œè¿™é€šå¸¸å®ç°â€œupsertâ€ï¼ˆå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥ï¼‰
                    vector_store.add_documents(documents=batch_docs, ids=batch_ids)
                    print(f"   âœ… ç¬¬ {batch_num} æ‰¹æ·»åŠ /æ›´æ–°æˆåŠŸã€‚")
                except Exception as e:
                    print(f"   âŒ ç¬¬ {batch_num} æ‰¹å¤„ç†å¤±è´¥: {e}")

            bm25 = BM25Retriever.from_documents(documents)
            hybrid_retriever = Chroma_Retriever(
                    retrievers=[bm25, vector_store],
                    weights=hybrid_retriever_weights,
                    flags=["bm25","vector"]
                )
            self.retriever = hybrid_retriever
            return self.retriever
        except Exception as e:
            logger.error(f"Failed to load vector store: {e}")
            raise

    def invoke(self, query: str) -> list[str]:
        """ä½¿ç”¨æ£€ç´¢å™¨è¿›è¡ŒæŸ¥è¯¢ã€‚"""
        try:
            if self.retriever is None:
                self.build_retriever()
            return self.retriever.invoke(query)
        except Exception as e:
            logger.error(f"Failed to invoke retriever: {e}")
            raise
    
    def add_doc(self, doc_list: list[str]):
        
        result = {}
        file_manager_activate.add_docs(doc_list) # å°†æ–‡ä»¶ä¿å­˜è‡³æœ¬åœ°

        for file_path in doc_list:
            # ä¿å­˜æ–‡ä»¶ä¿¡æ¯è‡³æ–‡ä»¶çš„é…ç½®æ–‡ä»¶ä¸­
            doc_hash = get_single_hash(file_path) + "." + file_path.split(".")[-1]
            doc_name = os.path.basename(file_path)
            if doc_hash not in self.config.FILE_LIST:
                chunks = self.parser._process_file(file_path)
                result[doc_name] = chunks
                self.docs[doc_name] = chunks
                self.config.FILE_LIST[doc_hash] = doc_name
        return result

    def save_local(self):
        # å°†self.docsä»¥pklæ ¼å¼ä¿å­˜åˆ°self.docs_dir
        with open(self.docs_dir, 'wb') as f:
            pickle.dump(self.docs, f)
        self.save_config()

    def list_docs(self):
        return list(self.docs.keys()) if isinstance(self.docs, dict) else []

    def list_chunks(self, doc_name):
        return self.docs.get(doc_name, []) if isinstance(self.docs, dict) else []
        
    def delete_docs(self, doc_name: str):
        """åˆ é™¤æŒ‡å®šæ–‡æ¡£"""
        if isinstance(self.docs, dict) and doc_name in self.docs:
            del self.docs[doc_name]
        

        
    def save_config(self):
        """
        ä¿å­˜æœ¬åœ°çŸ¥è¯†åº“çš„é…ç½®æ–‡ä»¶
        """
        with open(self.config_path, "w", encoding="utf-8") as f:
            json.dump(self.config.model_dump(), f, indent=4)